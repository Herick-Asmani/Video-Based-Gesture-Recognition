DATASET:
The dataset used for this project is Cambridge Hand Gesture Dataset. The data set consists of 900 image sequences of 9 gesture classes, which are defined by 3 primitive hand shapes and 3 primitive motions. 
Each class contains 100 image sequences (5 different illuminations x 10 arbitrary motions x 2 subjects).


INSTRUCTIONS:
1. sources folder includes the papers referred for this Project.
2. Both Dataset and model file can be accessed using the following google drive link:
https://drive.google.com/open?id=1Z7Su5yRdk5v4nhr8ec0dgXK6EelEwvc3 
3. src folder contains all the python files for this project. 
4. Run lrcn.py in src folder first if you want to train the model and change the path of data line 52 in lrcn.py file.
5. Run test.py in src folder to evaluate on real time video.
6. If you want to run the predefined model, first download the saved model from google drive and
 then change path of model which is 26th and 27th line of test.py file.








